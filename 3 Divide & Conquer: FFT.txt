Speaker 0    00:00    The following content is provided under a creative Commons license. Your support will help mit opencourseware continue to offer high quality educational resources for free to make a donation or view additional materials from hundreds of mit courses. Visit mit opencourseware@ocw.mit.edu.  
Speaker 1    00:21    All right, let's get started. Man. You can call me Eric and today we're going to do another divide and conquer algorithm called the fast 40 a transformed. It's probably the most taught algorithm at Mit. It's used in all sorts of contexts, especially a digital signal processing like MP3, compression, all sorts of things. Uh, but we're going to think about it today in the context of divide and conquer and polynomials. So let me remind you, I mean, this class is all about polynomial time, but usually with polynomial time. We only care about the lead term today and today only pretty much we're going to be thinking about all the terms in a polynomial. So my, I'll talk about polynomials, mostly a and b. You have a constant term and then linear term and a quadratic term, uh, up to. I will say that there are any terms, which means the last one is a n minus one.  
Speaker 1    01:28    So normally the degree of the polynomial here is n minus one. Uh, I wish that degree was defined to be in here, but whatever. I can't change the definitions and Algebra. So, uh, this is the traditional algebraic way of thinking about a polynomial. Uh, of course you can write it with summation notation a k x to theK , k equals zero to and minus one. We'll jump back and forth between them. I'm also going to introduce a vector notation for polynomials, uh, because, uh, so the ais are real numbers typically. Uh, we might change that at some point, um, but usually a common reason, maybe you don't care much about polynomials, but you definitely care about vectors. Any kind of one dimensional dataset is a string of real numbers. Like if you're sampling audio, like right now we're recording this a microphone. You're seeing lots of different, uh, the movement of the membrane and this microphone over time, you're sampling whatever, 40,000 times a second, each one you're measuring real number about where that thing is. That is a sequence of real numbers. Now you can convert it into a polynomial if you want. They're the same thing. X is not necessarily meaningful here. We really care about other coefficients. Okay? Now, given such a polynomial, there are three typical things we want to do. So these are the operations on polynomials.  
Speaker 1    03:04    I'll say why we want to do them in a second. So the obvious one, if you do care about x, is some kind of evaluation. So maybe I give you a polynomial of, and I give you a number. Let's call it x zero. And I want to compute what is a of zero. So if I plug in x, here's the general variable, but if I give you an actual real number, say for the x's, what does that add up to? Okay? Uh, so how would you solve evaluation before we go to the other operations? I mean, there's an obvious way. Uh, we, you know, compute all the terms and add them up, but if you do that naive Lee computing, uh, x to the K in this form, maybe computing x to the Cape maybe takes k multiplications and so the total running time will be quadratic, but we can do better than that. I know it's 11:00 too early in the morning to think.  
Speaker 2    04:25    Yeah,  
Speaker 1    04:31    good. Once you've completed x to theK , you can compute x to the k plus one and with one multiplication. And so you can compute all x to the ends in linear time and then do the, all the thing. You're basically doing a dot product between the x to the case and the, a vector. Cool. My first Frisbee. Uh, so that's one way to do it. Uh, there's a slightly slicker way to write it called Horner's role, but it's doing exactly the same thing that you said. Uh, it's, uh, this is just a nice algebraic way of writing. It is the same as a zero plus x times a one plus x times eight to plus and so on a x times and minus one. And then lots of closed parentheses, um, so this is a, of course equivalent to that expression by the law of distribution and uh, this is essentially doing the x's x products one at a time. So this is clearly order and addition and multiplication. So we get order and time in this lecture. Time is the number of arithmetic operations. That's our model. Assume it takes constant time to multiply or add a to real numbers.  
Speaker 1    06:01    Okay, cool. So evaluation that's easy. Linear time for today is good. Quadratic is bad. We want to be quadratic. Okay. Second thing you might want to do with polynomials is add them. The third thing is multiplying. So we're given to ponder meals, any of x and BMX and we want to compute a new polynomial, c of x. That is the summation. How do you define the summation? Well, you would like see to equal a of x plus B of x for all x. that's the definition. Of course, we can do it algebraically as well because, uh, these are numbers in the end for any excess evaluates a number. Uh, so if we add two polynomials of this forum, one with ai as one with the bis, all we're doing is adding corresponding ais and bis. So this is easy. We just need ck to equal a k plus bk for. Okay, so again, one of your time. No problem. Okay, third operation is the exciting one. The hard one to get good. Otherwise this lecture would be over in a couple more minutes. So multiplication, same deal. We're given an x box and we want to convert that into some cfx that for all x evaluates to the product of those two polynomials. Okay. How do we do this? Uh, we can't just multiply corresponding eight ks and became a, in fact, if you take a big thing like this, you multiply it by corresponding big thing, let's do it.  
Speaker 1    08:11    It doesn't look like fun. Uh, we get, let's see. So the constant term is just the product that's easy of the constant terms. Uh, but then if I take this product or this product, I get linear terms is going to be a one B, zero plus a zero b one times x. and then there's a quadratic term, which I get from switch colors, uh, this and this and this. So there's three things times x squared, and that's where I get tired. I'm going to switch to the summation notation. You a type, I didn't go to high school, but I assume in high school Algebra you learn this, a c, k as the sum of j Equals Zero K and j, b, k minus j. that's the general form because Aaj came from an x to thej  term became honest. Jay came from an x to the k minus j term. When you multiply those together, you get x to the k. So this is the coefficient of x to the K. Cool. So that's what we'd like to compute. Given A and B, we want to compute this polynomial. See how long does it take?  
Speaker 1    09:39    Do you do this for all k? So to compute the Keith term takes order k time. So total time is n squared.  
Speaker 3    09:52    So that's  
Speaker 1    09:53    not good for this lecture. We want to do better. In fact, today we will achieve,  
Speaker 3    10:01    uh, and login. That's our goal.  
Speaker 1    10:08    Polynomial multiplication in and log in. Why do we care about polynomial multiplication? Uh, because it's equivalent to another operation which we use all the time and digital signal processing, image editing, all sorts of different things which is convolution a convolution is usually thought of as an operation on vectors. Uh, so  
Speaker 1    10:46    remember this vector notation where we're just thinking about the coefficients x's are kind of irrelevant. Just thinking about a sequence of real numbers. Uh, so maybe that sequence of real numbers for a represents, um, I dunno, waveform, maybe this is the audio. I'm speaking now and then I take some other way form here. I have a Gaussian function, either my six squared and I want to take a for all possible shifts of this Gaussian. I want to compute the dop product between the blackboard and the piece of paper. Okay. That's some kind of smoothing function. If I wanted to clean up noise or something like that, you can do the same thing on a two dimensional image is a little harder to think about, but you can map a two dimensional image too, one dimensional vector, and you have a two dimensional galcion. If you ever do Gaussian Blur and photoshop a, this is what you're doing a convolution and it's used to like as if you're pretend that your lens was out of focus when you do that, uh, it's done in, in audio processing and all sorts of things. Uh, so formally you're given two vectors and you want to take all possible shifts of one vector and take the dot product with the other one. I have that written down, just that product. Same thing as inner product, which just means multiply corresponding positions and add them up.  
Speaker 1    12:22    And if you ignore this minus sign, that's exactly what this is doing is taking aj  versus B K is plus Jay. So that's the Bj vector. But with all possible shifts, k, we compute this for all. That's really cool. We're going to compute it in n log n time. All different end shifts of b will take the dot product with a kind of magical because it looks like you're doing n squared work, but we will do it in and log in time. The only issue is we have to reverse be a. Then the minus signs turn into plus signs and there's some boundary conditions, but it's basically the same. If we can sell polynomial multiplication, we can solve convolution. Cool. So that's why we care about multiplication. So how are we going to solve this? What I'd like to do is talk about alternate representations and polynomials. That's next thing here. We just did the operations. Let's talk about different representations. So we talked about this one representation. It's one way to represent and Amil, but it's not the only one. You probably know others. So on the one hand we have a representation. A is a coefficient factor.  
Speaker 1    13:49    We can write down the AIS. That was just one way to represent a meal. Can anyone give me another way to represent on a mill? I have two ways in mind. So yeah, generating function, isn't that the say? Oh, I guess in principle you could imagine like writing a recurrence on the generating function or something that's plausible in general. Generating functions are polynomials, if you know what that they are. Cool. So it doesn't quite answer the question. Yeah, sure. Sorry. Point representation. Yeah. Can I call them samples? I'm going to put that under. See a bunch of samples, a bunch of points on the polynomial. Uh, so like x, k, a, y, k, how many do we need? I think. And minus one should do it. We'll check. Yep. Uh, and if we are told that a six k equals Y K, and we're told that all the k's are distinct, then this uniquely determines the polynomial. If you have a degree and minus one polynomial and you have any samples, there's only one polynomial that passes through all those points. That's a, it's a consequence of the fundamental theory of, of, of Algebra that gives you uniqueness. Existence, I think was proved by genre in 17, 18, hundreds, long time ago. This is good. This is what we're going to use. There's another answer. I should give you a frisbee first.  
Speaker 1    15:40    Excited. Just wait until I hit you. Be less excited. Okay. So samples, coefficients, anything else? Yeah, roots. Yeah, roots is the other answer I was looking for, but it's not going to be so good. Algorithmically has. We'll see. Sorry. Um, so I could give you a sequence of risks. This is the fundamental theorem of Algebra that every polynomial is uniquely determined by its set of routes. If you allow roots with multiplicity, then every polynomial of degree and has exactly and roots. So this will be some sequence of r one, two, R and minus one. Um, and the polynomial would be given as you actually need a constant multiplier. But x minus R, zero x minus r one, that would be a polynomial. The trouble with roots is that if I give you a coefficient factor and I want to compute the roots, not only is it hard to do, it's impossible to do in our model.  
Speaker 1    16:48    If you're only allowed to add, subtract, multiply, divide, take square roots, take k throughts. Uh, there is no way to solve a polynomial of degree, five or larger. You know, there's quadratic formula formula formula. There is no quintek formulas and old result, 18 hundreds. So, uh, going from coefficient vector to roots takes infinite time. It's not so good. Uh, and in particular, if we think about our operations, a addition becomes really difficult. A multiplication is easy if I have to, a polynomials represented as a sequence of route, so I want to multiply them. That's just concatenating the vectors, a taking the union of the vectors of the, of their root lists, so that's cool. And multiplying the seas I guess, but addition is really hard because addition is sort of fundamentally about coefficient vectors. And then once you go there you can go from roots to coefficient factors and add them up, but then there's no relation between the roots of the, some of the polynomials versus the risk of the original. So it's, I don't know for sure that that's impossible. It's definitely very, very hard. Probably impossible. So, uh, let me draw a little table. Each of these representations has some advantages and a disadvantage in terms of these three operations. So on the one hand we have this sort of algorithms, we care about evaluation,  
Speaker 3    18:27    addition and multiplication.  
Speaker 1    18:38    And on the other axis we have our representations which are coefficient vectors, a roots samples. You'll see why I chose this order in a moment. It makes for a nice pretty matrix. Uh, so  
Speaker 1    19:04    we've talked about almost every cell in this matrix, but let me just summarize. So we started out just thinking about a coefficient vector and evaluation was linear time edition was linear time multiplication. So far is quadratic. Although our goal is to make n log n four roots. I just said multiplication is easy. That's linear time addition is really hard. Infinite time and evaluation, I guess that's linear time. In fact, the way it's written, you only have a linear number of subtraction and multiplication, so it's really easy to evaluate. And then sample vectors, we haven't talked much about that. So the idea is suppose you're given two polynomials with the same x case, we're going to fix x kids. All we need is that there are distinct. So xk could equal k for example, just a bunch of integers. And then we are told what polynomial a evaluates to at every X K and we're told what polynomial be evaluates to at every x k, so we're given some white ks and some Zika.  
Speaker 1    20:18    And then we want to compute, say the sum or the product of those two vectors. What do we do? Just add or multiply the corresponding a yK,  and z case, right? Because if we're told we want of x two equals a times B of x or Z, if x two equals x plus b of x for all x, well now we know what x is. We care about. We just do it at the x case. That's what we're told for a and for B. and so compute c of x k, it's just the somme are the product of why Kanzi k? Okay, so multiplication is really easy in the sample view, and this is why we're going to use this view. We're also going to use this view because as we'll see, there is a problem. A addition is easy, multiplication is easy, evaluation is annoying. How I can evaluate a of x k at or a of x at x k for anyK , but I can't evaluated at some, at some arbitrary value of x. okay, that's annoying. I'm told that these finite sample points, but now I have to somehow interpolate is called polynomial interpolation. We'll study it in numerical analysis and so on. You can do it. But uh, it takes quadratic time in general, best known algorithms or quadratic.  
Speaker 1    21:43    So this is bad. This is bad. This is bad. So no representation, perfect. Life sucks. Uh, what we'd like is to get the best of this one is really hard to work with because converting into roots is sort of impossible, is impossible in our, in an arithmetic model. So we're going to focus on column a and column C, we Kinda like to take the men have those two columns. We won't quite get that. What we will get is a, an algorithm for converting between these two representations in n log n time. Not quite linear, but close. And once we can do that, if we want to multiply two things in the coefficient land, we can convert to sample land, do it in linear time and then convert back. So, uh, that's the magical transformation we're going to cover. And it is called the fast for a transplant. February transformers, the algorithm discreet fourier transform. Is that transformation mathematically? Cool. So the whole name of the game is converting from Coefficient representation to samples or vice versa. It turns out they're almost the same. So that won't be obvious for a long time until the end of the class. Any questions before we proceed?  
Speaker 3    23:08    Yeah.  
Speaker 1    23:16    Ah, so, okay. The question is, uh, if I want to w we'll get there in a second, but if I want to multiply and it's so easy to do in sample. And why don't I just sample a and B and then multiply them. That's right. Uh, but effects sampling is not so easy. It takes a quadratic time. Let's go there. Now. <inaudible>, we have any samples to do each one cost linear time, a member to evaluate a polynomial. It takes linear time. If you want to think of it in a matrix that's entered the matrix, then we get a big matrix, so we're given the excise and we just want to evaluate a given polynomial who's coefficients are given by a zero, a one, two and minus one. Our goal is to compute the why's. Why zero y one y two Y, n minus one, and so you can, if you know a matrix vector product, you take this row with that column. You take the dot product that multiplies corresponding entries, you get y zero. That is the definition of the polynomial evaluation. I'm just gonna. Write a bunch of these rows. You get the pattern.  
Speaker 3    24:58    Pretty simple.  
Speaker 1    25:09    Okay. This is called the vendor Mond Matrix. I'll call it v and in general a have room for it. So  
Speaker 1    25:40    in general, if we look at the Ij, it's just. I'm sorry, you will may notice I'm not using the letter. I. We will get to why in a moment. Vj K, a row j, column k, that's going to be x subj  to the power. That's the vendor Mon Matrix. We can compute it in quadratic time, has quadratic entries, we can use the trick, the suggested earlier, compute each term from the previous one, a by multiplying by ex j a. and then we want to compute this matrix vector product, and you can clearly do it in quadratic time, uh, just computing each thing correspondingly, and that's sort of the best you can do without any further assumptions. So this takes a. So if I want to compute this product, that's the coefficients to samples problem, uh, this is the same thing as computing the, the AAV vector. So this is a matrix vector multiplication, which takes a end squared time.  
Speaker 2    26:52    Okay?  
Speaker 1    26:54    Okay. Um, the other hand. So that's a problem because we're trying to beat quadratic multiplication. So if we'd spend quadratic time to convert over here, it doesn't matter that this is linear time. There are two problems. One is that conversion costs too much. The others, we don't yet know how to cover it backwards. Uh, but this matrix view gives us also the reverse transformation if we want to convert samples. Two coefficients, uh, this is a notation I know is from Matlab. How many people know Mat lab? A bunch. So for you it's the backslash a. But uh, usually in linear Algebra, like 18. Oh six. You see you have a, you have, uh, some Matrix v times, some unknown vector. Usually it's called x here it's called a and you know the right hand side and you want to solve for this. How do you do it?  
Speaker 2    27:50    Sorry,  
Speaker 1    27:53    multiply by the inverse. Yeah, how do you do it in computer science? Galcion elimination. It turns out in versus the right answer here. But a Gaussian elimination would be the standard way to solve a linear system like that. The trouble with Kelsey and elimination is it takes cubic time and it's in its normal form. In this case it's a little bit special because this matrix is essentially fixed. The excise don't need to change. It could be XII is just eye or something. Uh, so we can, in this case, it's a little better to compute the inverse first. Uh, so we could also just do the inverse times a, uh, from a numerical analysis standpoint. This is very bad, but don't worry about it. For now, we're going to get a better algorithm today anyway, it doesn't involve matrix at all, but the nice thing is if a computing the inverse, that takes end cube time, but you only have to do at once.  
Speaker 1    28:49    So if you have to do this many times, you can do this product and end squared time. You just have to maintain that vion verse for once and for all. Okay. Uh, great. So we've got quadratic algorithms to go back and forth between these representations that at least tells us it's doable. But, uh, we, we of course need better than quadratic to improve on the naive multiplication algorithm. So that's what we're going to do. A in general, we can't do any better, but we have one freedom, which is we have said nothing about the x case. We can choose them to be whatever they we want them to be. I keep saying <inaudible> cake was Kay. That seems fine. It's actually really bad choice for reason that we will get to a, but there is a choice. We're magically. This transformation becomes easy and can do it in n log n time. Before we get there, I want to give you some motivation for how this could possibly work  
Speaker 1    30:14    and as you might expect, even just from the n log n running time, we're going to be using divide and conquer. So let's just think about how a divide and conquer could work. Uh, and I'm gonna. Show you an idea and then we'll figure out how that idea could possibly work at the. It doesn't work at the moment, but we will be able to choose the Xk so that it works. So let's say the goal, I mean, what we want to do is compute this v Times A. I'm going to convert that back into matrix, into polynomial a land. So our goal is to compute amx for all x in some set x.  
Speaker 1    31:04    okay, this is a taking a bunch of samples, just set x is just a set of the x case, but I'm going to change that set in a moment, uh, using recursion. So I want to think. So the input to this algorithm is a polynomial, amx, and it's a set capital x of positions that I'd like to evaluate that polynomial at. This is clearly more general than the problem we're trying to solve and I'm going to solve it with divide and conquer and divide and conquer. There are three steps, divide, conquer, and combine. All right, so let's start with divide.  
Speaker 3    31:43    Here's the big idea. A,  
Speaker 1    31:48    I would say there are two natural ways to divide a vector. One is in the middle, that's what we've always seen with merge sort and divide and conquer or convicts hall from last time. But there's another way which will work better here, which is the even entries and the odd entries. So I'm going to divide into even and odd coefficients.  
Speaker 1    32:15    So let me write that down. One of them is called ace of even of x. that's a polynomial. It's going to have half the degree, so it's going to be some from k equals zero. Two I wrote in here, but I think I want something like an over two minus one and minus one over to one of those things. Uh, a, a two k x to the k. So really, really what I want, which is easier to write it in the vector notation. I want all the even entries. Okay? I want to try to figure out what the last one is, but it's roughly and number two ish, just right that you could go a little bit extra. That's fine. Uh, if you define a sub and to be zero and a seven plus one to be zeroed, all those to be zero. Those terms will disappear.  
Speaker 1    33:10    So the key thing here is I'm taking the even entries, but I'm an, I'm not, I don't have to k up here. Alright. So this is the x to the zero term. This is the x to the one term. This is the x to the two term. So there's a difference between x to the case and that the, a sub two k, but I mean, just think about it in vector form. Don't worry about the Algebra for now. We're going to have to worry about in a second, right? Intuitively, what I want to do is extract from the vector of all the ais. Uh, these two vectors, the odd coefficients in order and the even coefficients in order, but I'm going to need the Algebraic form and a moment for the combined step. It should be two k plus one x to the K.  
Speaker 2    34:05    okay?  
Speaker 1    34:06    That's step one. Easy to do linear time of course. Um, let's jump ahead to step three combined in order to compute a of x. from what I'd like to do is recursively compute a even of x and a out of x. for some values x, it's not going to be x and x is going to be some other set. And let's think about how I could compute of given some solutions to a even if x and a hot of x. So this is step  
Speaker 2    34:43    three, combine.  
Speaker 1    34:52    So, uh, I would like a of x over here and I want a even of something and a odd of something and some thing in here. Uh, anyone see the Algebra?  
Speaker 2    35:19    Maybe start with this. I hear a mumble. Yeah. X squared. Exactly. Getting why  
Speaker 1    35:38    x squared, because we have this mismatch here. We have a sub two. K, we want x to the two. K, how could we do that? Well, we could put x squared to the two K and x squared, x squared to the k is the same thing as x to the two k. okay, and so magically this transforms into the even entries of Amx. That's half of them. We do the same thing for the odd ones and we're almost there. Now we have a sub twoK  plus one times x to the twoK , no plus one. So how can I turn it at a plus one? Multiply by x out here, take the whole thing, multiply by x. Then I get all of the odd terms of amx. I add these together and get a Amex. Okay? It's A. I mean you could prove this more carefully, but a sort of that's just Algebra to see that this is correct.  
Speaker 1    36:42    Once you have this, it tells you what I need to do is compute a even have x squared for all x and x. So this is a four x and X. There's a for loop for you. So that's going to take linear time. If I already know this value and I already know this value, I do one multiplication, one addition, and boom, I get a of x. So in the conquer step, I want to recursively compute a, I'll call it a even of y and a odd of y, four y and x squared. X squared is the set of squares of all numbers in X. Okay, so I'm changing my set x. I started with a polynomial, a and a set x recursively. I'm doing a different polynomial of half the degree, half the number of terms, uh, but with a different set of the same size. Okay. I started with x. x squared has the same size as extra. So let's try to figure out how fast or slow this algorithm is, but that is a divide and conquer that is going to be our golden ticket. Pretty simple.  
Speaker 1    38:24    Uh, but we're going to need another trick. So I'm, I'm gonna write a recurrence. Now this, this recurrence depends kind of on two things. One is how many terms are there in that we've been calling in and the other is how many numbers are there in x? How many different places do I have to evaluate my polynomial? So we've got t of and that was called size of x. okay. Uh, so fighting, conquer, goes hand in hand with recurrences. Generally you've got the recursive part. So that's just how big are the sub problems? How many are there? There are two sub problems. They have half the size in terms of end, but they have the same size in terms of x, so two times because there's two sub problems each of size and over to a and size x. okay. Plus what goes here is however much it costs to do the divide, step plus, however much it costs to do the combined step, all the non recursive parts.  
Speaker 1    39:32    Well this is just partitioning the vectors. Linear scan, linear time. Uh, this is, we talked about. It's a constant number of arithmetic operations for each x. So this costs order x time, this cost order end time, right? So in general we get and plus x. Now this is not, again, not a recurrent solvable by the master method because it has two variables. And uh, so probably the. Usually when you're faced with this sort of thing, you want to do kind of back of the envelope picture, draw a recursion tree, a good way to go. So at the root, now I know that initially x equals n right when I started out, I have an coefficients I have and different positions I want to evaluate at them at because that's what I want to do to do this conversion from coefficients to samples. So at the root of the recurrent tree, I'm just going to write an order and work to get started.  
Speaker 1    40:31    And to the do the recurrence, there are two recursive calls. One has both have size and number two in terms of a and they have sides the same x which is also known as n in those two recursion. So in fact the linear work here will be in an end and then we'll get in. An x never goes down, so x always remains in the original value of n. This is a bad recurrence there n sorry. There are login levels. That's the good news. Once we get down to constant size, we can kind of stop when there's only one coefficient I know how to evaluate the polynomial with, with just a zero. That's easy. Uh, so, uh, down at the bottom here at the last level. So this is the height log in the last level is just, it's again going to be a whole bunch of events all the same and here and is the original value of x because we haven't changed that. How many ads are there? Down here? Hmm. To, to the log in. Also known as end.  
Speaker 2    41:36    Yeah.  
Speaker 1    41:41    Good. So we had a. because we had login levels, we had binary branching, so it's two to the number of levels which is just an. So this is squared. All of this work still in square.  
Speaker 1    42:01    Clearly what we need is for x to get smaller to. Right. If x, if in this recursion let me enrich, draw the recursion I would like to have. If x became x over to here, this is the only change we need then and an exchange and exactly the same way. And so then we can just forget about x. it's going to be the same as n. Then we get two times one over two plus order. End look familiar. It is bread and butter. Recurrence merge sort recurrence. That's again, that's what we need to do somehow when we convert our set x to x squared, I want x to get smaller because that are all plausible. Let's think about it. What's the base case? Um, keep things simple. Let's say the base case when x equals one. I'll just let x be. Let's say I want to compute a my Aa at one. Keep it simple. Okay? What if I. What if I want to values and x? I'd like to have the feature that when I square all the values and x, so I want to values, but when I square them, I only have one value  
Speaker 1    43:38    solve for X.  
Speaker 2    43:44    Yeah, negative one and one not bad. Good catch. Negative one and one that could work right?  
Speaker 1    43:59    What are negative one on one there? The square roots of one negative one squared is one. One squared is one. There's two square roots for every number, two square roots for every number. Interesting. So that means if I just keep taking square roots when I squared them, it collapses by factor of two. Uh, let me,  
Speaker 2    44:22    let me go to another board defined something.  
Speaker 1    44:35    You're all anticipating what's going to happen, but I'm going to say collapsing, set. A set is collapsing if either, um, the size of x squared is the size of x divided by two, uh, and recursively x squared is collapsing  
Speaker 1    45:04    because I need this to work all the way down the recursion or I need a base case which was just x equals one. It was a single item in x. So I happened to start with x equals the item one. It didn't have to be one, it could have been seven. It couldn't be zero because zero, uh, he won't get two numbers. There's only one square root of zero. Okay? So I lied a little bit other than zero. Every number has exactly two square roots. So what's the square root of negative one? I so complex numbers. So if I take square roots of these guys, I get and negative by. And again, I get minus one and one.  
Speaker 1    45:51    Okay? That's when x equals four. Turns out this is only going to work for powers of two, but hey, if it isn't a power of to just round up to the next power of two, that only hurts me by a factor of two k complex numbers. Okay? Every time I said real number in the past, pretend they said complex number. Everything I said is still true. Actually, the root thing is only true when you allow complex numbers. Some Paulo meals have complex rates. Okay, so pretend I said complex. We're going to need complex numbers. This is why, because when we start taking square roots, we immediately get a complex numbers. Okay? Next would be x equals eight. A squirt of I squared up. I see if I can do it should be route to over two times, one plus I. and then this one is just the bird of negative. It is going to be two over two times, one minus Pi. And then we have all our old guys.  
Speaker 3    47:00    Uh  
Speaker 1    47:03    Oh. And then I can, right? Plus or minus in front of each of these. It's like what are warrior enough terms there? Okay, now I've got eight. Sorry, I've got four numbers here. I've got four numbers there. How in the world could I remember this? Maybe I memorize it. No, I didn't memorize it. It's actually really easy to figure this out. If you know geometry, geometry, let's do geometry over here. It's convenient. I am actually a geometer, you know, complex numbers have two parts, right? The real part and the complex part. I'm going to draw that in what's called the complex plane, where we draw the real part here and I guess it's usually called the imaginary part on the y axis. Every point in this plane is a complex number and vice versa. The same thing.  
Speaker 2    48:02    Okay,  
Speaker 1    48:04    so what did we start with? We started with the number one number one will be here. It has no imaginary part, so it's on the x axis. That's. This is the real line down here and it's at position one, which I'm going to just find to be right there. Okay. Then we got negative one that's over here. Then we got high. That's here one time I. Then we got negative. I that's here. Then we've got two over two times I plus one that's here, Richard over to buy to over to. What is the property of <inaudible> over to come over to. Over to. That has distanced exactly one to the origin, right? If I draw this triangle route to over to, over to, over to A. I square this, I get a half a square. This I get a half, add them together. I get one, take the square root and I still get one. So this distance is one interesting. Uh, and then I got the negative of that which is over here and negative that. Alright. And then this is the negative. I get it wrong. Yup. Sorry it doesn't matter, but I'll think of it as I minus two.  
Speaker 1    49:26    I'm minus one. It's the same because I had the plus and minus, but I liked the geometry. So this point is a negative route to over to buy route two over two. And then there's the negative over here. The properties of these points have,  
Speaker 2    49:50    I heard a word  
Speaker 1    49:52    unit circle will say to you in a circle, it's a unit circle, right? Clearly that deserves a frisbee end. Okay. Unit Circle. Circle seems good. Uh, what's going on here is I took this number. I claimed it was the square root of it because it turns out if you take points on the unit circle in the complex plane, when you square a number, it's like doubling the angle relative to the x axis. This is angle zero. This is angle we've call 45 degrees. This is angle 90 degrees. So when I square this number, I get 90 degrees. That's why this number is a square. Sorry, is the square root of. I probably should have labeled some of these. This is I. This is mine. This is mine. This one. And this is one in general. We get something called A.  
Speaker 3    51:08    Yeah.  
Speaker 1    51:11    So let's. These are called the roots of unity.  
Speaker 1    51:19    You're going to do is just a fancy word for one. One is here, and first we computed the square roots of one. They were minus 101. Then we compute computed the fourth roots of one. All of these numbers, if you take the fourth routes or sorry, if you take the fourth power, you get one. Then we computed the eighth writs of one. All of these numbers, if you take the eighth power, you get one again, so in general and through acts of humanity, we're gonna assume and as a power of two, but this notion actually makes sense for any end and they're just uniformly spaced around the circle and if you know some geometry and how it relates to Trig, you know that a general point on the circle is coast theta sine theta x coordinate is coast data y coordinate science data. This is also a funny notation for complex numbers. Not so funny. This is the geometric interpretation of a coast Feta a plus. I signed Feta can if I want them uniformly spaced around the circle and I want to include this point also known as data equals zero because when fat equals zero cost data is one sine theta zero right? Then, so I want to say for Feta equals to zero and then a here, I'm going to get fancy towel over n two over N, two n minus one over and now what's towel to Pi? Thank you.  
Speaker 1    53:00    This is a modern notation just over the last couple of years, but I believe in town so much. I got it tattooed on my arm. Okay. Tau Is, is the fundamental constant screw pie. Uh, none of that three and change six and changes where it's at. So tell clearly this is much nicer towel over and not two Pi over in Tau is a whole circle. This circle two ends of a circle and minus one over into the circle. I didn't do an answer of a circle because that's also the same as zero.  
Speaker 2    53:37    Okay. Now why a,  
Speaker 1    53:45    why did I introduce this notation? Because there's this other great thing called or there's formula a which is the, this, this equals e to the I  
Speaker 2    53:59    a Beta, right? Double check.  
Speaker 1    54:09    It's so rare that I get to do real a calculus. This is formula e for or another number to unchange a e to the I. This is funny because it's complex times data is equal to coast data. Plus I signed data. This is the relation between exponentials and trigonometry. That's big thing. Or there did cool. Uh, so what, because this lets us understand how squares work, not squares the shape squares the operation  
Speaker 1    54:50    when I take squares a. So if I take you to the iphone and this is one of my roots of unity, let me, let me expand that with Feta. So Feta is some k times towel over n. let's do this. My first. So in reality we have a k town and when I square it, that's the same thing as putting the two right here. This is the same thing as eating the I times to theta. Bingo. I get what I was claiming that if I started some angle feta relative to the x axis, when I square the number, I just doubled the angle. This is why, okay, this is obvious, uh, and just from regular Algebra and then this thing or there's formula tells me that corresponds to doubling the angle on a circle. It's the only works for points on the circle. But uh, so when I go here, I get you to the k, I guess two k times towel brand twice as far around the circle. All right, a fine. What happens if I take this number and I square it? So this has a really big angle. This is a one half plus one eighth, whatever that is, a five eighths. The Times Tau, when I double that angle, I go  
Speaker 3    56:25    to here  
Speaker 1    56:28    now this, you might call it 10 eights or you might also call it one quarter. So there's a cause when you go around the circle, you stay on the circle. So there's another thing going on which is really, um, this is e to the I times to theta mob towel. Usually we think of Mons is relative to integers. But uh, what I mean is every time I add a multiple of town, nothing changes. If I go around the circle five times and then do something, same as just doing the something. Okay? So I kind of need that. Um, and this is true because a e to the I tau equals one. You may know it as e to the I pi equals negative one, but clearly this is a superior formula. So superior, I got a tattooed on my other arm.  
Speaker 1    57:20    It's amazing what you can do with a laser printer and a temporary tattoo kit, sadly for last, but definitely try it at home. Cool. So either the Tau equals one. So going around the circle, same thing is not. All right. So, uh, you can draw on this picture for every number. What is it? Square. And in general, if you look at these four guys there squares, we're just going to be these two guys. If you look at these four guys, they're squares are going to be among these four guys. So I started with eight guys. I squared them, I get four square them, I get to, I squared them, I get one. That's how we constructed it. Uh, but you can see it works not only for this eight point set that we constructed sort of by hand, uh, but it works for the roots of unity as long as an, as a power to this set of points will be collapsing. Okay? So if an he has a power to two, so manager k, then a and roots of unity  
Speaker 3    58:31    are collapsing  
Speaker 1    58:42    according to this definition and that's what we want. Then this divide and conquer algorithm runs and n log n time because every time we square the set x, we reduced the size by a factor of two, so we get 10 equals two times 10 over two plus n let's order and that order and login. And so this whole thing we compute. In other words, we set x k to be m, e to the I k town over n now because I should say how to compute that, but let's just say that's given to you for free. It takes constant time to compute each ruthie unity. In fact, again, we only do this once and for all for each value van, so you can think of it as just being part of the algorithm. These are the <inaudible> we use. I said <inaudible> could be anything we want as long as they're all different.  
Speaker 1    59:34    So I'm going to choose them to be ben uniformly spaced points around the complex unit circle, and then magically this algorithm runs an n log n time. It's pretty cool a intuitively you think a real number is x squared. Of course it has the same size as x, but once you go to complex numbers, there's this nifty trick where you start with one 10th of the circle and you uniformly spaced points after the first level of recursion. You'll only have to be dealing with over two of those points, namely the even ones also known as the over to threats of unity and after the next level of recursion is to andover for roots of unity and so on. So this recursion is well defined. When you have a vector of size n you just have to deal with the entrance of unity and you're happy. That is fast fourier transform. That algorithm with these excise is fft. So let me write this somewhere. It kind of snuck up on us. This is the Oregon and we were aiming to find pass for you. Transform, uh, is that divide and conquer algorithm on the right  
Speaker 3    01:11    already  
Speaker 1    01:13    abstractly for something called the dft. The discrete for a transform  
Speaker 1    01:25    is the corresponding mathematical transformation. Fast is about an algorithm. Screed is about discrete math. So dmt is a, this thing that we wanted to compute, which was basically the Product v Times a Number v was the vendor bond matrix, uh, but, and it was, it depended on all these x case, uh, and we're gonna set x k to be this easy to the I k town over. And so, uh, if you remember the of the k a k here was a ex j to the cave power. So this just becomes a e to the I, J k over and uh, it's a little funny. These are all consecutive because this is a totally different. But uh, that's the matrix. If you take that Matrix Times vector that is called the discreet fourier transform, the vector and fft is a way to compute it and then log in time. You just run this algorithm and for those x it'll just work and then login time.  
Speaker 1    02:48    Cool. But if you remember way back to the beginning, what we needed is a way this converts a coefficient factor into a sample of vector. Then we can multiply the matrices, but we then need to trance. Sorry, multiply the polynomials. Then we need to transform the sample vector that results back into a coefficient vector. So we're only half done. I only have 15 minutes. Luckily the other half is almost identical to this half. So let's do that next, uh, maybe over here. So we've got our great divide and conquer algorithm. What we need now, let me give you the polynomial multiplication algorithm. All right, let's call this sounds more exotic, fast polynomial multiplication. Fascinating. And again, let's say that were given to a polynomials and be represented in coefficient form.  
Speaker 1    04:00    What we need is I'll call a star, which is the result of running and 50 on a discrete for a transform of a. These star do the same thing. So we know what this means is convert a from a coefficient vector into a sample vector, convert b from a coefficient vector into a sample vector. Now I have the samples of a star at the roots of unity. These guys and I have the samples of be at the exact same points, the roots of unity. So I can compute seastar the, the transformed version of the dft of see is just the, uh, I mean Seastar k equals a star k times beast. Rk. This is the multiplication algorithm, uh, for sample vectors, right? We started with that. That has, that's linear time. And then the missing piece is I need to recompute c, which is the inverse fast fourier transform, a sea star. So this is the missing link, so to speak. We need to be able to go backwards in this transformation.  
Speaker 1    05:32    Good news is the is not going to change what we're computing isn't going to change. All this is going to change, or the x case. Why? Because I remember from the top right now we know how to Compute v Times a well. We now need to compute is the inverse times a. So the only question is what is the inverse? This matrix has a super special structure. It's metrics, looks lots of crazy, lots of points on a circle. Maybe the inverse has a nice structure and it does claim His v inverse is v Complex conjugate divided by n a, what's complex conjugate for a geometer. It's reflection through the x axis for an Algebra person, a plus b. The complex conjugate is a minus ib. Okay, so just apply that to every entry in the Matrix and the divide all the entries by n you get the inverse.  
Speaker 1    06:50    Cool. Very cool. Because what this tells us is we run exactly the same algorithm and do exactly the same transformation. If we want to do the inverse, we can actually just use vi, but with a different choice of x, k, namely for the inverse, call it x k inverse. We just take the complex conjugate of this thing which turns out to be a e to the minusj  town over n and divide the whole thing. My end. Okay. I'm using a fact here, which is that the complex conjugate of this number is actually just you put a minus sign here. Why is that holds? Because geometry, right? If you. Feta is usually measuring the counterclockwise angle from the x axis. If you take the complex conjugate, you go from up here to down here, the reflection through the x axis. That's the same thing as if you measure data is a clockwise angle from the x axis. And that's the same thing as negating the angle. Okay? So that's just a little geometry. You can prove it algebraically or the, I don't know how off hand, it's not, not hard. Uh, so if I want to take some angle and then flip it through, the x axis is the same as the negative of the angle. So complex conjugate of this number is same thing with the minus sign. And then we have to divide by n. If I just, uh,  
Speaker 3    08:31    did I lie a,  
Speaker 1    08:35    I can't divide my answer in the wrong spot. I used these x case and then I applied the transform. I take this thing, I get not quite the universe, but I ended up getting envy inverse. I multiply that by my, a star that's going to give me any times, eh?  
Speaker 3    08:57    Okay. Uh,  
Speaker 1    09:02    so, uh, then I just take that back to our divided by n boom. I've got the inverse transform. So this is how you do a inverse fourier transform. You just flip the sign in the exponent, in the case, then you do the same, a matrix vector product, and then you divide by n and then you've done the inverse. So that's how you do a, if you believe this claim, that's how you do this last step question. Oops. No, Jay, sorry. Uh, I was imagining the, these guys, it's just k thank you. The questions. Okay. So what remains is to prove this clan everybody happy? If I, uh, I should probably have better. Wow. Anyway, that's not the best. I'm going to call this a vk pro x k prime. Then when I do, when I plugged that in, I get a different matrix. The prime and what I'm claiming with this claim says is that v Prime is equal to n times the inverse. So I apply the same fft algorithm, but with v Prime instead of V, then I get not quite the product I want, but just end times of product. I want divide every turn by end and we get the inverse because this cool thing about complex numbers here we get another cool thing. All right? Uh, but we have to prove this claim. So let's do a little bit of Algebra. No pain, no gain, right? A good.  
Speaker 1    10:45    So, uh, let's look at Bj k prime,  
Speaker 3    10:52    so. Oh, sorry.  
Speaker 1    11:04    So let's, uh, fine. Let's look at p, the product of the and v Complex country. Okay, what else? Calling v prime up there. Uh, I claim that this thing is n times the identity matrix with one's down, the diagonal and Zeros everywhere else. Okay. So let's look at this product in general. Let's look at the, uh, say the J K eighth item and the product that's going to come from roadj  of the a dot product with column k of the complex conjugate. Now the matrices here are symmetric, so actually rows and columns are the same, but that's the general definition of the cell and the product of two matrices.  
Speaker 1    11:57    So let's write it out as a summation. We have from m equals zero. It's so hard not to use it for my summation is the only class I have to do it because I've already taken. But I guess I still use capital high, but uh, we'll use em. It is complex number today. Uh, so we have um, eat the. I tell Jay I'm over n times e to the minus. I amK  over N. I don't know why I changed the order. I put the towel here instead of there, but same thing. Okay. This is just the, for every, a position I am in the cell and corresponding position in. Sorry, I'm in the row of corresponding position and in the column I have j. m and I have mk against the order. Doesn't matter. Symmetric, but I'm getting it right here. This is, we're using this formula.  
Speaker 1    13:03    Okay. I put a minus sign here because this is the comp, the complex conjugate. Okay. So now I just do some Algebra. These share a lot. They share it, they share em and they share the divided by N. okay. So this is some m equals zero and minus one e to the I. Oh, they also share a towel. A towel am overran times. Jay Minus K, please correct me if I make any mistakes. Uh, cool. So it depends how jnk relates. Of course. Um, if j equals k, that's also, that's also known as something on the diagonal. I want this, I want the Matrix and, and, and, and zero zero. Right? Soj  equals k, that's the diagonal. That's where I want to get in. And indeed, if j equals k, this becomes zero. So all of this becomes zero. E to the zero is one. And so I'm summing up one end times and get in. Okay, cool. That's one case. This is an if j equals k. and somehow I claimed it everywhere else I get Zeros. So let's prove that. So if Jane Does Not Equal K, I'm going to rewrite this a little bit. Jnk or fix. Okay. And is changing in the sun. So I want to write this as some m equals zero to n minus one  
Speaker 1    15:09    to the eye.  
Speaker 2    15:12    Uh,  
Speaker 1    15:15    Jay minus k over n Times M. Okay. In other words, this thing, race to the nth power. What is this series?  
Speaker 2    15:33    One word?  
Speaker 1    15:36    Geometric. Thank you. This is a geometric series and uh, I guess I should've waited to give you the Frisbee until you tell me how do you solve the geometric series with a finite term. So think of this as z to the M.  
Speaker 2    15:54    Yeah, the formula.  
Speaker 1    15:59    Just Z. Z to the n minus one. Almost over z minus one. That's great. If you have some of z to theK , k equals zero and minus one. That's that. It's in the appendix of Your Textbook. So we just plug that in and we get to be a shock to the I Tao j minus k over n to the nth power minus one. Over to the. I actually the denominator it doesn't really matter because this is supposed to be zero. So it's all about the numerator. Uh, so, but it's same thing minus one. Okay.  
Speaker 2    16:53    Where's My red, red?  
Speaker 1    16:56    The end cancels with the end.  
Speaker 1    17:00    This is an integer not equal to zero. So we have e to the I towel to an integer power. What's either the towel one? Okay. Convenient. I have that there. One minus one is zero. So we get zero satisfying. Okay, so that proves this claim. We've proved that on the diagonal we get in because we had copies of one off the diagonal, we get zero like this, therefore v compliment or sorry, v Complex conjugate times and is inverse. Therefore, this algorithm actually computes the inverse fast fourier transform. So that's it for algorithms today. Um, but let me quickly tell you about some applications. Uh, you've probably taken other classes that use applications have already transformed. So I will just summarize. If you've ever edited audio, you probably did it in a, unless you're just like pasting audio clips together, uh, you probably did it in what's called frequency space.  
Speaker 1    18:11    So you know that as I talked about in the beginning, when we're measuring where the membrane on this microphone goes over time that is in, in the time domain for every time we sample where physically this thing is. If you apply, I think the way I defined it here, it's the inverse fast fourier transform. Usually it's called four year transform to that, a time domain vector, you get a new vector. Now it's a complex vector have started with real numbers. You get complex numbers, so for every position in the vector, what it corresponds to, the x axis is no longer time. Now it's frequency. For every frequency you're measuring a, essentially you're viewing this, this vector, the wave form as a bunch of a metric function, say sign of something times data. If you look at one of the entries in the vector and it's a complex number, if you compute the magnitude of the complex number, the length of the vector of length of that to coordinate and factor that is how much stuff have that frequency you have.  
Speaker 1    19:15    And then the angle of the vector into d is a how that a trigger metric function has shifted in time. So if you take a pure note, like if I was playing a bell and it's exactly c major, you, uh, you know, it looks, it looks really wavy. It's actually a nice, perfect a sine curve with some offset depending on when I hit it. And then if you apply the fourier transform where you get Zeros everywhere except for the one frequency that's appearing. And there you get one and everyone else who gives zero, well one possibly rotated, depending on the face, and you can take any audio stream converted by for you transform, do manipulations there. For example, you've probably heard of high pass filters that removes all the high frequencies are low pass filters, remove all the low frequencies, you just convert to this space and zero out the parts you want.  
Speaker 1    20:07    And then you convert back with inverse fourier transform. If you've used adobe audition or audacity, they can all do these things, uh, and there are tons of context were converting to 40 space. Makes life easy. And in general, if you have any time based signal, you should always think about what do you get with fft when you transformed to a frequency based signal. And you can do lots of cool things you couldn't do otherwise. And it only takes them log in time. Plus people do it in the hardware. There is a fast implementation called fft w the fastest fourier transform in the West, which has made here at mit a bunch of years ago. And it's still the best software implementation of FFT. So people use it everywhere. Your head, your noise canceling headsets, probably use it. MP3 is it? It's a cool algorithm. 
